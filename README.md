# ğŸ§  OnemedAI â€“ AI Radiology Report Comparator

OnemedAI is an advanced AI-powered tool that compares **AI-generated radiology reports** with **radiologist-written reports**, identifies key differences, and enables interactive exploration using local or cloud-based LLMs.

---

## ğŸ”§ Prerequisites

Before running the app, ensure you have the following installed:

- âœ… Python 3.8 or higher  
- ğŸ§  [Ollama](https://ollama.com/) â€“ for running LLAMA 3 locally  
- ğŸ” [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) â€“ for text extraction from scanned PDFs  

---

## ğŸš€ Installation & Setup

### ğŸ“¦ 1. Install Python Dependencies

```bash
pip install -r requirements.txt
```

### ğŸ” 2. Set Up Environment Variables

Create a `.env` file in the root directory and add the following:

```env
GOOGLE_API_KEY=your-google-api-key
DEPLOYED=False
```

### ğŸ¤– 3. Set Up LLAMA 3 with Ollama

Download and start LLAMA 3 (8B model):

```bash
ollama run llama3
```

---

## ğŸ§ª Usage

### â–¶ï¸ 1. Run the Streamlit App

```bash
streamlit run app.py
```

---

### ğŸ  2. Home Page â€“ Report Comparison

Upload and compare two PDF reports:

- ğŸ“„ **Upload Reports**: AI vs Radiologist  
- ğŸ§  **Choose Scan Type**:
  - Document-Level  
  - Sentence-Level  
  - Preprocessed Sentence-Level  
- ğŸ” **Select Embedding Method**:
  - Count Vectorizer  
  - TF-IDF Vectorizer  
  - All-MiniLM-L6-v2
- âœ… Click **Submit** to view:
  - Similarity score
  - Highlighted text differences
  - AI interpretation summary

---

### ğŸ’¬ 3. ChatBot Page â€“ Ask Questions to the PDFs

- ğŸ“š Load PDFs into a vector database
- ğŸ’¡ Choose your LLM (LLAMA 3 or Gemini)
- ğŸ¤– Ask questions related to the content of both PDFs
- ğŸ§© View interactive responses from the AI

---

## ğŸ“ Project Structure

```
OnemedAI/
â”œâ”€â”€ app.py                     # Main Streamlit application
â”œâ”€â”€ compare.py                 # PDF comparison logic
â”œâ”€â”€ pdf_extractor.py           # PDF text extraction logic
â”œâ”€â”€ text_preprocessing.py      # Preprocessing logic
â”‚
â”œâ”€â”€ LLM/                       # LLM integrations
â”‚   â”œâ”€â”€ gemini.py              # Google Gemini API
â”‚   â”œâ”€â”€ llama3.py              # LLAMA 3 via Ollama
â”‚   â””â”€â”€ prompt.py              # Prompt crafting
â”‚
â”œâ”€â”€ embeddings/                # Embedding techniques
â”‚   â”œâ”€â”€ CountVectorizer.py
â”‚   â”œâ”€â”€ TfidfVectorizer.py
â”‚   â””â”€â”€ all_MiniLM_L6_v2.py
â”‚
â”œâ”€â”€ result.py                  # Chatbot result formatting
â”œâ”€â”€ requirements.txt           # Python dependencies
â””â”€â”€ .env                       # Environment variables (not included)
```

---

## ğŸ“„ License

This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgements

- [Streamlit](https://streamlit.io/) â€“ Web UI framework  
- [Meta LLAMA 3](https://llama.meta.com/llama3/) â€“ Open-weight large language model  
- [OLLAMA](https://ollama.com/) â€“ Local LLM runner  
- [ChromaDB](https://www.trychroma.com/) â€“ Vector database  
- [LangChain](https://www.langchain.com/) â€“ LLM orchestration framework

---

## ğŸ‘¨â€ğŸ’» Author

**Vilas PK**  
GitHub: [@VILAS07](https://github.com/VILAS07)  
LinkedIn: [linkedin.com/in/vilaspk](https://www.linkedin.com/in/vilaspk)

---

> ğŸ’¬ â€œEmpowering radiology through AI-driven understanding and transparent comparison.â€
```
